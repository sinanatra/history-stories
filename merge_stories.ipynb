{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Down the Rabbit hole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch queries from Google Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "json_file = \"history.json\"\n",
    "\n",
    "data = []\n",
    "with open(json_file) as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "query = []\n",
    "for i in data[0]:\n",
    "    query.append(i[\"title\"])\n",
    "\n",
    "#pprint(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split queries by words + adds token.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26862\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "\n",
    "print(len(query))\n",
    "\n",
    "maxquery = 20000\n",
    "\n",
    "if len(query) >= maxquery:\n",
    "    query = query[:maxquery]\n",
    "\n",
    "print(len(query))\n",
    "\n",
    "doc = nlp(str(query))\n",
    "\n",
    "keep = []\n",
    "for sent in doc.sents:\n",
    "    \n",
    "    #for each word\n",
    "    for token in sent:\n",
    "        if token.is_alpha:\n",
    "            keep.append([token.orth_, token.tag_])\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Export', 'VB'], ['History', 'NN'], ['Chrome', 'NNP'], ['Web', 'NN'], ['Store', 'NNP'], ['macos', 'NNP'], ['Export', 'NNP'], ['history', 'NN'], ['from', 'IN'], ['chome', 'JJ'], ['browser', 'NN'], ['Super', 'NNP'], ['User', 'NNP'], ['export', 'NN'], ['chrome', 'NN'], ['history', 'NN'], ['json', 'NNP'], ['Cerca', 'NNP'], ['con', 'NN'], ['Google', 'NNP'], ['stack', 'VB'], ['overflow', 'NN'], ['export', 'NN'], ['history', 'NN'], ['json', 'NNP'], ['Cerca', 'NNP'], ['con', 'NN'], ['Google', 'NNP'], ['javascript', 'NNP'], ['Using', 'VBG'], ['Google', 'NNP'], ['Chrome', 'NNP'], ['extensions', 'NNS'], ['to', 'TO'], ['import', 'VB'], ['export', 'NN'], ['JSON', 'NNP'], ['files', 'NNS'], ['Stack', 'NNP'], ['Overflow', 'NNP'], ['export', 'NN'], ['history', 'NN'], ['json', 'NNP'], ['Cerca', 'NNP'], ['con', 'NN'], ['Google', 'NNP'], ['Super', 'RB'], ['History', 'NNP'], ['Cache', 'NNP'], ['Cleaner', 'NNP']]\n"
     ]
    }
   ],
   "source": [
    "print(keep[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch a txt and splits it into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lewis Carroll \\n  \\n  \\n  \\n CHAPTER I', \" Down the Rabbit-Hole \\n  \\n Alice was beginning to get very tired of sitting by her sister on the \\n bank, and of having nothing to do: once or twice she had peeped into the \\n book her sister was reading, but it had no pictures or conversations in \\n it, 'and what is the use of a book,' thought Alice 'without pictures or \\n conversations?' \\n  \\n So she was considering in her own mind (as well as she could, for the \\n hot day made her feel very sleepy and stupid), whether the pleasure \\n of making a daisy-chain would be worth the trouble of getting up and \\n picking the daisies, when suddenly a White Rabbit with pink eyes ran \\n close by her\", \" \\n  \\n There was nothing so VERY remarkable in that; nor did Alice think it so \\n VERY much out of the way to hear the Rabbit say to itself, 'Oh dear! \\n Oh dear! I shall be late!' (when she thought it over afterwards, it \\n occurred to her that she ought to have wondered at this, but at the time \\n it all seemed quite natural); but when the Rabbit actually TOOK A WATCH \\n OUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on, \\n Alice started to her feet, for it flashed across her mind that she had \\n never before seen a rabbit with either a waistcoat-pocket, or a watch \\n to take out of it, and burning with curiosity, she ran across the field \\n after it, and fortunately was just in time to see it pop down a large \\n rabbit-hole under the hedge\", ' \\n  \\n In another moment down went Alice after it, never once considering how \\n in the world she was to get out again', ' \\n  \\n The rabbit-hole went straight on like a tunnel for some way, and then \\n dipped suddenly down, so suddenly that Alice had not a moment to think \\n about stopping herself before she found herself falling down a very deep \\n well']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "book = open(\"alice.txt\")\n",
    "\n",
    "sentences = []\n",
    "for split in book.read().split(\".\"):\n",
    "    sentences.append(split.replace(\"\\n\",\" \\n \"))\n",
    "    #sentences.append(split.replace(\"\\n\",\" \\n \").lower())\n",
    "    \n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split txt by words + adds token.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "\n",
    "doc = nlp(str(sentences))\n",
    "\n",
    "book_token = []\n",
    "for sent in doc.sents:\n",
    "    \n",
    "    for token in sent:\n",
    "        book_token.append([token.orth_, token.tag_])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', '-LRB-'], [\"'\", '``'], ['Lewis', 'NNP'], ['Carroll', 'NNP'], ['<', 'XX'], ['br><br><br><br', 'XX'], ['>', 'XX'], ['CHAPTER', 'NN'], ['I', 'PRP'], [\"'\", \"''\"]]\n",
      "\n",
      "[['Export', 'VB'], ['History', 'NN'], ['Chrome', 'NNP'], ['Web', 'NN'], ['Store', 'NNP'], ['macos', 'NNP'], ['Export', 'NNP'], ['history', 'NN'], ['from', 'IN'], ['chome', 'JJ']]\n"
     ]
    }
   ],
   "source": [
    "print(book_token[:10])\n",
    "print(\"\")\n",
    "print(keep[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "filter_by_category = lambda my_list, category: [ word for word, cat in my_list if cat == category ]\n",
    "randomized = [ (random.choice(filter_by_category(keep, cat)) if cat == \"NNP\" or cat == \"JJ\"  or cat == \"NN\"  else word, cat) for word, cat in book_token ]\n",
    "\n",
    "output = open(\"index.html\",\"w\")\n",
    "output.write(\"<html><head><link rel='stylesheet' type='text/css' href='style.css'></head><body><header>Part of speech from Alice's Adventures in Wonderland have been replaced by the same type of word classes which were randomly retrieved by an algorithm from my browser history.<br> <p class=NNP>Proper Noun</p><p class=NN>Noun</p><p class=JJ> Adjectives</p></header><section><h3>Alice's Adventures in my Browser history</h3>\" )\n",
    "\n",
    "for text, tag in randomized[ 2 : 100000 ]:\n",
    "    if r'\"' in text:\n",
    "        continue\n",
    "    if r\"'\" == text:\n",
    "        continue\n",
    "    if r'\\n' in text:\n",
    "        output.write(\"\\n\")\n",
    "    else:\n",
    "        output.write('<p class='+tag+'>'+text+'</p>' )\n",
    "\n",
    "output.write('</section></body></html>' )\n",
    "output.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
